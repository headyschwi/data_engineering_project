{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1115f37-8833-4b6b-8716-957b2fd31d95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[MountInfo(mountPoint='/databricks-datasets', source='databricks-datasets', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volumes', source='UnityCatalogVolumes', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-tracking', source='databricks/mlflow-tracking', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks-results', source='databricks-results', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-registry', source='databricks/mlflow-registry', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volume', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/volumes', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/', source='DatabricksRoot', encryptionType=''),\n",
       " MountInfo(mountPoint='/volume', source='DbfsReserved', encryptionType='')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dbutils.fs.mounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ba102d5-e648-4748-bc31-2eeeb8b91349",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount point /mnt/bronze already exists.\n"
     ]
    }
   ],
   "source": [
    "existing_mounts = dbutils.fs.mounts()\n",
    "target_mount_point = \"/mnt/bronze\"\n",
    "\n",
    "if any(mount.mountPoint == target_mount_point for mount in existing_mounts):\n",
    "    print(f\"Mount point {target_mount_point} already exists.\")\n",
    "else:\n",
    "    configs = {\n",
    "        \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "        \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "    }\n",
    "\n",
    "    dbutils.fs.mount(\n",
    "        source = \"abfss://bronze@datalakeheadyschwi.dfs.core.windows.net/\",\n",
    "        mount_point = target_mount_point,\n",
    "        extra_configs = configs\n",
    "    )\n",
    "\n",
    "    print(f\"Mount point {target_mount_point} successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd67682-eccb-4d00-a5ea-c096ae869982",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount point /mnt/silver successfully created.\n"
     ]
    }
   ],
   "source": [
    "existing_mounts = dbutils.fs.mounts()\n",
    "target_mount_point = \"/mnt/silver\"\n",
    "\n",
    "if any(mount.mountPoint == target_mount_point for mount in existing_mounts):\n",
    "    print(f\"Mount point {target_mount_point} already exists.\")\n",
    "else:\n",
    "    configs = {\n",
    "        \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "        \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "    }\n",
    "\n",
    "    dbutils.fs.mount(\n",
    "        source = \"abfss://silver@datalakeheadyschwi.dfs.core.windows.net/\",\n",
    "        mount_point = target_mount_point,\n",
    "        extra_configs = configs\n",
    "    )\n",
    "\n",
    "    print(f\"Mount point {target_mount_point} successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac908f0c-a4a9-4492-bd1e-452be3742939",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mount point /mnt/gold successfully created.\n"
     ]
    }
   ],
   "source": [
    "existing_mounts = dbutils.fs.mounts()\n",
    "target_mount_point = \"/mnt/gold\"\n",
    "\n",
    "if any(mount.mountPoint == target_mount_point for mount in existing_mounts):\n",
    "    print(f\"Mount point {target_mount_point} already exists.\")\n",
    "else:\n",
    "    configs = {\n",
    "        \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "        \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "    }\n",
    "\n",
    "    dbutils.fs.mount(\n",
    "        source = \"abfss://gold@datalakeheadyschwi.dfs.core.windows.net/\",\n",
    "        mount_point = target_mount_point,\n",
    "        extra_configs = configs\n",
    "    )\n",
    "\n",
    "    print(f\"Mount point {target_mount_point} successfully created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3b6505a-7747-4bc4-835e-a5268caad5c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[MountInfo(mountPoint='/databricks-datasets', source='databricks-datasets', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/gold', source='abfss://gold@datalakeheadyschwi.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volumes', source='UnityCatalogVolumes', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/silver', source='abfss://silver@datalakeheadyschwi.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-tracking', source='databricks/mlflow-tracking', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks-results', source='databricks-results', encryptionType=''),\n",
       " MountInfo(mountPoint='/databricks/mlflow-registry', source='databricks/mlflow-registry', encryptionType=''),\n",
       " MountInfo(mountPoint='/mnt/bronze', source='abfss://bronze@datalakeheadyschwi.dfs.core.windows.net/', encryptionType=''),\n",
       " MountInfo(mountPoint='/Volume', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/volumes', source='DbfsReserved', encryptionType=''),\n",
       " MountInfo(mountPoint='/', source='DatabricksRoot', encryptionType=''),\n",
       " MountInfo(mountPoint='/volume', source='DbfsReserved', encryptionType='')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dbutils.fs.mounts()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Storage Mount",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
